{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397716f1",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Image Classification using Deep and Hand-Crafted Feature Modeling </h1>\n",
    "<h1 style=\"text-align: center;\"> Computer Vision Laboratory Assignment 9 </h1>\n",
    "<h2 style=\"text-align: center;\"> 122CS0067 Amiya Chowdhury 27/03/2025 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780d405",
   "metadata": {},
   "source": [
    "<h3>1.\tExtract deep features from the pre-trained VGG-16 model and extract hand crafted Histogram Oriented Gradient (HOG) features for MNIST dataset. Stack the deep features with HOG features and model it using a random forest classifier to classify the MNIST dataset. Run the hybrid model 5 times and compute the mean accuracy. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49c68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from skimage.feature import hog\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38617443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1875/1875 [==============================] - 642s 342ms/step\n",
      "313/313 [==============================] - 110s 352ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST images for VGG16 (convert to RGB and resize)\n",
    "x_train_vgg = np.array([tf.image.resize_with_pad(np.stack([img]*3, axis=-1), 32, 32).numpy() for img in x_train])\n",
    "x_test_vgg = np.array([tf.image.resize_with_pad(np.stack([img]*3, axis=-1), 32, 32).numpy() for img in x_test])\n",
    "\n",
    "# Normalize images to match VGG16 input requirements\n",
    "x_train_vgg = x_train_vgg / 255.0\n",
    "x_test_vgg = x_test_vgg / 255.0\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=tf.keras.layers.Flatten()(base_model.output))\n",
    "\n",
    "# Extract deep features\n",
    "train_features_vgg = feature_extractor.predict(x_train_vgg)\n",
    "test_features_vgg = feature_extractor.predict(x_test_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c68755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    return np.array([hog(img, pixels_per_cell=(4, 4), cells_per_block=(2, 2), feature_vector=True) for img in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9634ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy over 5 runs: 0.9786\n"
     ]
    }
   ],
   "source": [
    "train_features_hog = extract_hog_features(x_train)\n",
    "test_features_hog = extract_hog_features(x_test)\n",
    "\n",
    "# Stack VGG16 and HOG features\n",
    "x_train_combined = np.hstack((train_features_vgg, train_features_hog))\n",
    "x_test_combined = np.hstack((test_features_vgg, test_features_hog))\n",
    "\n",
    "# Run Random Forest model 5 times\n",
    "accuracies = []\n",
    "for _ in range(5):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_combined, y_train)\n",
    "    y_pred = clf.predict(x_test_combined)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f\"Mean Accuracy over 5 runs: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753883ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1296)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_hog.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf9bca",
   "metadata": {},
   "source": [
    "<h3>2.\tExtract deep features from the pre-trained VGG-16 model and extract hand crafted Scale Invariant Feature Transform (SIFT) features for MNIST dataset. Stack the deep features with SIFT features and model it using a random forest classifier to classify the MNIST dataset. Run the hybrid model 5 times and compute the mean accuracy. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da013c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import SIFT\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e10b506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sift_features: (60000, 128)\n",
      "Shape of sift_features: (10000, 128)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "sift_features_train = []  \n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "for img in x_train:     \n",
    "    gray_image = img\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "        \n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        sift_features_train.append(np.zeros(128, dtype=np.float32))\n",
    "    else:\n",
    "        mean_descriptor = np.mean(descriptors, axis=0)\n",
    "        sift_features_train.append(mean_descriptor)\n",
    "\n",
    "sift_features_train = np.array(sift_features_train)\n",
    "print(\"Shape of sift_features:\", sift_features_train.shape)\n",
    "\n",
    "sift_features_test = []  \n",
    "\n",
    "for img in x_test:     \n",
    "    gray_image = img\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "        \n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        sift_features_test.append(np.zeros(128, dtype=np.float32))\n",
    "    else:\n",
    "        mean_descriptor = np.mean(descriptors, axis=0)\n",
    "        sift_features_test.append(mean_descriptor)\n",
    "\n",
    "sift_features_test = np.array(sift_features_test)\n",
    "print(\"Shape of sift_features:\", sift_features_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d60e3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_sift = sift_features_train\n",
    "test_features_sift = sift_features_test\n",
    "\n",
    "# Stack VGG16 and SIFT features\n",
    "x_train_combined2 = np.hstack((train_features_vgg, train_features_sift))\n",
    "x_test_combined2 = np.hstack((test_features_vgg, test_features_sift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f40de25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.8       ,  0.        ,  0.        , ..., 30.        ,\n",
       "         1.8       ,  1.2       ],\n",
       "       [ 7.6       , 30.5       , 25.4       , ..., 26.2       ,\n",
       "        18.8       , 13.6       ],\n",
       "       [13.333333  ,  3.6666667 ,  0.33333334, ..., 28.5       ,\n",
       "         4.        ,  0.33333334],\n",
       "       ...,\n",
       "       [28.8       , 36.4       ,  1.        , ..., 41.        ,\n",
       "        17.4       ,  1.        ],\n",
       "       [16.428572  ,  1.        ,  0.14285715, ..., 12.857142  ,\n",
       "         1.4285715 ,  2.        ],\n",
       "       [66.6       , 18.6       ,  4.6       , ..., 23.4       ,\n",
       "         2.8       ,  0.2       ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aef72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy over 3 runs: 0.9456\n"
     ]
    }
   ],
   "source": [
    "# Run Random Forest model 3 times (to reduce time taken)\n",
    "accuracies2 = []\n",
    "for _ in range(3):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_combined2, y_train)\n",
    "    y_pred = clf.predict(x_test_combined2)\n",
    "    accuracies2.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy2 = np.mean(accuracies2)\n",
    "print(f\"Mean Accuracy over 3 runs: {mean_accuracy2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd22e6",
   "metadata": {},
   "source": [
    "<h3>3.\tExtract deep features from the pre-trained VGG-16 model and extract hand crafted SIFT and HOG features for MNIST dataset. Stack the deep features with HOG and SIFT features and model it using a random forest classifier to classify the MNIST dataset. Run the hybrid model 5 times and compute the mean accuracy. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb32510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy over 3 runs: 0.9789\n"
     ]
    }
   ],
   "source": [
    "# Deep, HOG, SIFT features combined\n",
    "x_train_combined3 = np.hstack((train_features_vgg, train_features_sift, train_features_hog))\n",
    "x_test_combined3 = np.hstack((test_features_vgg, test_features_sift, test_features_hog))\n",
    "\n",
    "# Run Random Forest model 3 times\n",
    "accuracies3 = []\n",
    "for _ in range(3):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_combined3, y_train)\n",
    "    y_pred = clf.predict(x_test_combined3)\n",
    "    accuracies3.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy3 = np.mean(accuracies3)\n",
    "print(f\"Mean Accuracy over 3 runs: {mean_accuracy3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca65841",
   "metadata": {},
   "source": [
    "<h3>4.\tExtract deep features from the pre-trained VGG-16 model and extract hand crafted SIFT and HOG features for MNIST dataset. Stack the deep features with HOG and SIFT features and use PCA to transform and reduce the dimension (Test using different component values). Model the transformed features using a random forest classifier to classify the MNIST dataset. Run the hybrid model 5 times and compute the mean accuracy.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "defe2953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy over 3 runs (PCA 8): 0.3132\n",
      "Mean Accuracy over 3 runs (PCA 10): 0.3057\n",
      "Mean Accuracy over 3 runs (PCA 12): 0.2969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#12 components PCA \n",
    "x_train_reduced12 = PCA(n_components=12).fit_transform(x_train_combined3)\n",
    "x_test_reduced12 = PCA(n_components=12).fit_transform(x_test_combined3)\n",
    "\n",
    "x_train_reduced10 = PCA(n_components=10).fit_transform(x_train_combined3)\n",
    "x_test_reduced10 = PCA(n_components=10).fit_transform(x_test_combined3)\n",
    "\n",
    "x_train_reduced8 = PCA(n_components=8).fit_transform(x_train_combined3)\n",
    "x_test_reduced8 = PCA(n_components=8).fit_transform(x_test_combined3)\n",
    "\n",
    "\n",
    "# Run Random Forest model 3 times\n",
    "accuracies8 = []\n",
    "for _ in range(3):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_reduced8, y_train)\n",
    "    y_pred = clf.predict(x_test_reduced8)\n",
    "    accuracies8.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy8 = np.mean(accuracies8)\n",
    "print(f\"Mean Accuracy over 3 runs (PCA 8): {mean_accuracy8:.4f}\")\n",
    "\n",
    "# Run Random Forest model 3 times\n",
    "accuracies10 = []\n",
    "for _ in range(3):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_reduced10, y_train)\n",
    "    y_pred = clf.predict(x_test_reduced10)\n",
    "    accuracies10.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy10 = np.mean(accuracies10)\n",
    "print(f\"Mean Accuracy over 3 runs (PCA 10): {mean_accuracy10:.4f}\")\n",
    "\n",
    "# Run Random Forest model 3 times\n",
    "accuracies12 = []\n",
    "for _ in range(3):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=None)\n",
    "    clf.fit(x_train_reduced12, y_train)\n",
    "    y_pred = clf.predict(x_test_reduced12)\n",
    "    accuracies12.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute mean accuracy\n",
    "mean_accuracy12 = np.mean(accuracies12)\n",
    "print(f\"Mean Accuracy over 3 runs (PCA 12): {mean_accuracy12:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb7530",
   "metadata": {},
   "source": [
    "<h3>5.\tDraw conclusions on the best model among the above four models for classifying MNIST dataset.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bd73974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies were as follows:\n",
      "RF over VGG16,HOG features = 0.9786\n",
      "RF over VGG16,SIFT features = 0.9456\n",
      "RF over VGG16,HOG,SIFT features = 0.9789\n",
      "RF over PCA 8 reduced VGG16,HOG,SIFT features = 0.3132\n",
      "RF over PCA 10 reduced VGG16,HOG,SIFT features = 0.3057\n",
      "RF over PCA 12 reduced VGG16,HOG,SIFT features = 0.2969\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies were as follows:\")\n",
    "print(f\"RF over VGG16,HOG features = {mean_accuracy:.4f}\") #5 runs\n",
    "print(f\"RF over VGG16,SIFT features = {mean_accuracy2:.4f}\") #3 runs\n",
    "print(f\"RF over VGG16,HOG,SIFT features = {mean_accuracy3:.4f}\") #3 runs\n",
    "print(f\"RF over PCA 8 reduced VGG16,HOG,SIFT features = {mean_accuracy8:.4f}\") #3 runs\n",
    "print(f\"RF over PCA 10 reduced VGG16,HOG,SIFT features = {mean_accuracy10:.4f}\") #3 runs\n",
    "print(f\"RF over PCA 12 reduced VGG16,HOG,SIFT features = {mean_accuracy12:.4f}\") #3 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1502bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random forest model over the VGG16,HOG,SIFT features performed the best(accuracy=0.9789)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The random forest model over the VGG16,HOG,SIFT features performed the best(accuracy={mean_accuracy3:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638dec39",
   "metadata": {},
   "source": [
    "<h3>The random forest model over the VGG16,HOG,SIFT features performed the best (third model) (accuracy=0.9789)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d99fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
